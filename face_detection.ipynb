{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxrMvxh6yj/HbfwVYHttPm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/niravmistry09/face-detection-/blob/main/face_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WR7By_G2ftM6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cee54fe-4559-4f1e-a52c-a2efff83787a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: face-recognition in /usr/local/lib/python3.12/dist-packages (1.3.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.13.0.90)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: face-recognition-models>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from face-recognition) (0.3.0)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.12/dist-packages (from face-recognition) (8.3.1)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.12/dist-packages (from face-recognition) (19.24.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from face-recognition) (11.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install face-recognition opencv-python numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import face_recognition\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from datetime import datetime\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from IPython.display import display, Javascript\n",
        "import pytz"
      ],
      "metadata": {
        "id": "yJEqO3-CrnJH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/Training_Images'\n",
        "images = []\n",
        "classNames = []\n",
        "myList = os.listdir(path)"
      ],
      "metadata": {
        "id": "tBwHOaq8rhng"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myList"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-A3Zh9cWYNl",
        "outputId": "142c64d5-d832-4d19-8ffd-1660cb7c960a"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hardik_pandya.jpg',\n",
              " 'guru_randhawa.jpg',\n",
              " 'mukesh_ambani.jpg',\n",
              " 'shahrukh_khan.jpg',\n",
              " 'rahul_gandhi.jpg',\n",
              " 'nirav_mistry.jpeg',\n",
              " 'virat_kohli.jpg',\n",
              " 'Narendra_Modi.jpg',\n",
              " 'neeraj_chopra.jpg',\n",
              " 'salman_khan.jpg',\n",
              " 'abdul_kalam.jpg']"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for cl in myList:\n",
        "    curImg = cv2.imread(f'{path}/{cl}')\n",
        "    images.append(curImg)\n",
        "\n",
        "    name = os.path.splitext(cl)[0]\n",
        "    classNames.append(name)\n",
        "\n",
        "print(f\"Total Images Found: {len(images)}\")\n",
        "print(f\"Names: {classNames}\")"
      ],
      "metadata": {
        "id": "asnrjsqPgvA3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7364cfc-9f62-4935-f306-2d3371338428"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Images Found: 11\n",
            "Names: ['hardik_pandya', 'guru_randhawa', 'mukesh_ambani', 'shahrukh_khan', 'rahul_gandhi', 'nirav_mistry', 'virat_kohli', 'Narendra_Modi', 'neeraj_chopra', 'salman_khan', 'abdul_kalam']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def findEncodings(images):\n",
        "    encodeList = []\n",
        "\n",
        "    for img in images:\n",
        "        # BGR2RGB\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # 2. Chehre ke 128 unique points (encoding) nikalna\n",
        "        encode = face_recognition.face_encodings(img)[0]\n",
        "        encodeList.append(encode)\n",
        "\n",
        "    return encodeList\n",
        "\n",
        "encodeListKnown = findEncodings(images)\n",
        "print('Encoding Complete!')"
      ],
      "metadata": {
        "id": "4wKuLqHBgvDh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bad72e4-74e5-47f7-8f0a-9fed9e5df62d"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding Complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDC0NuexPK3y",
        "outputId": "9300788f-c250-46c5-c964-3774577d3bc4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytz in /usr/local/lib/python3.12/dist-packages (2025.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def markAttendance(name):\n",
        "    with open('Attendance.csv', 'r+') as f:\n",
        "        myDataList = f.readlines()\n",
        "        nameList = []\n",
        "\n",
        "        for line in myDataList:\n",
        "            entry = line.split(',')\n",
        "            nameList.append(entry[0])\n",
        "\n",
        "        # 2. Check karna: Agar naam list mein nahi hai, tabhi entry karna\n",
        "        if name not in nameList:\n",
        "            IST = pytz.timezone('Asia/Kolkata')\n",
        "            now = datetime.now(IST)\n",
        "            dtString = now.strftime('%H:%M:%S')\n",
        "            f.writelines(f'\\n{name},{dtString}')\n",
        "            print(f\"Attendance Marked for: {name}\")"
      ],
      "metadata": {
        "id": "hbRRUIV2rWUq"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Javascript, display\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import face_recognition\n",
        "\n",
        "# def get_frame_and_close():\n",
        "#     js = Javascript('''\n",
        "#         async function getFrame() {\n",
        "#             // 1. Camera start karna\n",
        "#             const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "#             const video = document.createElement('video');\n",
        "#             video.srcObject = stream;\n",
        "#             await video.play();\n",
        "\n",
        "#             // 2. Sirf ek frame capture karna\n",
        "#             const canvas = document.createElement('canvas');\n",
        "#             canvas.width = 640; canvas.height = 480;\n",
        "#             canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "\n",
        "#             // 3. Sabse important: Hardware tracks ko turant band karna\n",
        "#             stream.getTracks().forEach(track => track.stop());\n",
        "#             video.remove();\n",
        "\n",
        "#             return canvas.toDataURL('image/jpeg', 0.8);\n",
        "#         }\n",
        "#     ''')\n",
        "#     display(js)\n",
        "#     return eval_js('getFrame()')\n",
        "\n",
        "\n",
        "# print(\"Scanning... (Camera light will turn off after detection)\")\n",
        "\n",
        "try:\n",
        "    found = False\n",
        "    while not found:\n",
        "        # Camera on -> Capture -> Camera off (In one go)\n",
        "        data = get_frame_and_close()\n",
        "\n",
        "        img_bytes = b64decode(data.split(',')[1])\n",
        "        img = cv2.imdecode(np.frombuffer(img_bytes, np.uint8), 1)\n",
        "        imgS = cv2.cvtColor(cv2.resize(img, (0,0), None, 0.25, 0.25), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        facesCurFrame = face_recognition.face_locations(imgS)\n",
        "        encodesCurFrame = face_recognition.face_encodings(imgS, facesCurFrame)\n",
        "\n",
        "        for encodeFace in encodesCurFrame:\n",
        "            matches = face_recognition.compare_faces(encodeListKnown, encodeFace)\n",
        "            faceDis = face_recognition.face_distance(encodeListKnown, encodeFace)\n",
        "            matchIndex = np.argmin(faceDis)\n",
        "\n",
        "            if matches[matchIndex] and faceDis[matchIndex] < 0.6:\n",
        "                name = classNames[matchIndex].upper()\n",
        "                print(f\"✅ Recognized: {name}. Closing System.\")\n",
        "                markAttendance(name)\n",
        "                found = True\n",
        "                break\n",
        "\n",
        "        if not found:\n",
        "            print(\"No match, retrying...\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"Stopped:\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "9o4NBc6rFTnM",
        "outputId": "5615a26d-44a5-41f1-a28a-4d42dfd44e54"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function getFrame() {\n",
              "            // 1. Camera start karna\n",
              "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "            const video = document.createElement('video');\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "            \n",
              "            // 2. Sirf ek frame capture karna\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = 640; canvas.height = 480;\n",
              "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "            \n",
              "            // 3. Sabse important: Hardware tracks ko turant band karna\n",
              "            stream.getTracks().forEach(track => track.stop());\n",
              "            video.remove();\n",
              "            \n",
              "            return canvas.toDataURL('image/jpeg', 0.8);\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Recognized: NIRAV_MISTRY. Closing System.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import face_recognition\n",
        "import numpy as np\n",
        "\n",
        "# 1. Test image ka path (Jo image aapne upload ki hai)\n",
        "test_image_path = '/content/hardik_pandya.jpg' # Yahan apni file ka naam likhein\n",
        "\n",
        "# 2. Image load karein\n",
        "test_img = cv2.imread(test_image_path)\n",
        "test_img_rgb = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# 3. Test image mein face dhundna aur encode karna\n",
        "faces_in_frame = face_recognition.face_locations(test_img_rgb)\n",
        "encodes_in_frame = face_recognition.face_encodings(test_img_rgb, faces_in_frame)\n",
        "\n",
        "# 4. Matching Logic\n",
        "for encodeFace, faceLoc in zip(encodes_in_frame, faces_in_frame):\n",
        "    # Purani 'encodeListKnown' se compare karna\n",
        "    matches = face_recognition.compare_faces(encodeListKnown, encodeFace)\n",
        "    faceDis = face_recognition.face_distance(encodeListKnown, encodeFace)\n",
        "\n",
        "    matchIndex = np.argmin(faceDis)\n",
        "\n",
        "    if matches[matchIndex]:\n",
        "        name = classNames[matchIndex].upper()\n",
        "        print(f\"Match Found: {name} (Confidence: {round((1-faceDis[matchIndex])*100, 2)}%)\")\n",
        "\n",
        "        # Attendance mark karna\n",
        "        markAttendance(name)\n",
        "\n",
        "    # else:\n",
        "    #     print(\"Unknown Person Detected\")\n",
        ""
      ],
      "metadata": {
        "id": "WaLR0BJBgvPK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "742feeac-fb82-48ab-a9b6-b180907529f7"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Match Found: HARDIK_PANDYA (Confidence: 100.0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x1sX9Uh5KtSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9dam4emEKtO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g8P_EKYEKtLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7c9hEfnBKtI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_SWbxTgZKtFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "reR0FDncKtCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oZnzCllgKs_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L56innQ6Ks87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O4yrEaAUKs6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OrhxXAVxKs3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6QFx0gm7Ks0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# --- 1. Take Photo Function (Colab Fixed) ---\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript(''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture Face';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    '')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename\n",
        "\n",
        "'''\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UcBbNb7RmqVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3YWfovOoFYsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import cv2, numpy as np, face_recognition\n",
        "# from google.colab.output import eval_js\n",
        "# from base64 import b64decode\n",
        "\n",
        "# def get_frame():\n",
        "#   js = \"\"\"\n",
        "#     async function getFrame() {\n",
        "#       if (!window.video) {\n",
        "#         window.video = document.createElement('video');\n",
        "#         window.video.srcObject = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "#         await window.video.play();\n",
        "#       }\n",
        "#       const canvas = document.createElement('canvas');\n",
        "#       canvas.width = 640; canvas.height = 480;\n",
        "#       canvas.getContext('2d').drawImage(window.video, 0, 0);\n",
        "#       return canvas.toDataURL('image/jpeg', 0.8);\n",
        "#     }\n",
        "#   \"\"\"\n",
        "#   display(Javascript(js))\n",
        "#   return eval_js('getFrame()')\n",
        "\n",
        "# --- Main Logic ---\n",
        "# print(\"System Live... (Stop karne ke liye Interrupt karein)\")\n",
        "# try:\n",
        "#     while True:\n",
        "#         # 1. Automatic frame capture\n",
        "#         data = get_frame()\n",
        "#         img_bytes = b64decode(data.split(',')[1])\n",
        "#         img = cv2.imdecode(np.frombuffer(img_bytes, np.uint8), 1)\n",
        "\n",
        "#         # 2. Recognition (Small image for speed)\n",
        "#         imgS = cv2.cvtColor(cv2.resize(img, (0,0), None, 0.25, 0.25), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "#         facesCurFrame = face_recognition.face_locations(imgS)\n",
        "#         encodesCurFrame = face_recognition.face_encodings(imgS, facesCurFrame)\n",
        "\n",
        "#         for encodeFace in encodesCurFrame:\n",
        "#             matches = face_recognition.compare_faces(encodeListKnown, encodeFace)\n",
        "#             faceDis = face_recognition.face_distance(encodeListKnown, encodeFace)\n",
        "\n",
        "#             if True in matches:\n",
        "#                 matchIndex = np.argmin(faceDis)\n",
        "#                 name = classNames[matchIndex].upper()\n",
        "#                 print(f\"Recognized: {name} ({round((1-faceDis[matchIndex])*100)}%)\")\n",
        "#                 markAttendance(name)\n",
        "\n",
        "#                 recognized = True\n",
        "#                 break\n",
        "#             else:\n",
        "#                 recognized = False\n",
        "\n",
        "# except Exception as e:\n",
        "#     print(\"Stopped:\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "I3usSzvr_82D",
        "outputId": "fff8dc0b-e5b3-4494-d982-8a5c7c40d21a"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "System Live... (Stop karne ke liye Interrupt karein)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function getFrame() {\n",
              "            if (!window.video) {\n",
              "                window.video = document.createElement('video');\n",
              "                window.video.srcObject = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                await window.video.play();\n",
              "            }\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = 640; canvas.height = 480;\n",
              "            canvas.getContext('2d').drawImage(window.video, 0, 0);\n",
              "            return canvas.toDataURL('image/jpeg', 0.8);\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recognized: NIRAV_MISTRY (55%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function getFrame() {\n",
              "            if (!window.video) {\n",
              "                window.video = document.createElement('video');\n",
              "                window.video.srcObject = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                await window.video.play();\n",
              "            }\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = 640; canvas.height = 480;\n",
              "            canvas.getContext('2d').drawImage(window.video, 0, 0);\n",
              "            return canvas.toDataURL('image/jpeg', 0.8);\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recognized: NIRAV_MISTRY (56%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function getFrame() {\n",
              "            if (!window.video) {\n",
              "                window.video = document.createElement('video');\n",
              "                window.video.srcObject = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                await window.video.play();\n",
              "            }\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = 640; canvas.height = 480;\n",
              "            canvas.getContext('2d').drawImage(window.video, 0, 0);\n",
              "            return canvas.toDataURL('image/jpeg', 0.8);\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recognized: NIRAV_MISTRY (57%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function getFrame() {\n",
              "            if (!window.video) {\n",
              "                window.video = document.createElement('video');\n",
              "                window.video.srcObject = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                await window.video.play();\n",
              "            }\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = 640; canvas.height = 480;\n",
              "            canvas.getContext('2d').drawImage(window.video, 0, 0);\n",
              "            return canvas.toDataURL('image/jpeg', 0.8);\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recognized: NIRAV_MISTRY (55%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function getFrame() {\n",
              "            if (!window.video) {\n",
              "                window.video = document.createElement('video');\n",
              "                window.video.srcObject = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                await window.video.play();\n",
              "            }\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = 640; canvas.height = 480;\n",
              "            canvas.getContext('2d').drawImage(window.video, 0, 0);\n",
              "            return canvas.toDataURL('image/jpeg', 0.8);\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recognized: NIRAV_MISTRY (51%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function getFrame() {\n",
              "            if (!window.video) {\n",
              "                window.video = document.createElement('video');\n",
              "                window.video.srcObject = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                await window.video.play();\n",
              "            }\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = 640; canvas.height = 480;\n",
              "            canvas.getContext('2d').drawImage(window.video, 0, 0);\n",
              "            return canvas.toDataURL('image/jpeg', 0.8);\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recognized: NIRAV_MISTRY (54%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function getFrame() {\n",
              "            if (!window.video) {\n",
              "                window.video = document.createElement('video');\n",
              "                window.video.srcObject = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                await window.video.play();\n",
              "            }\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = 640; canvas.height = 480;\n",
              "            canvas.getContext('2d').drawImage(window.video, 0, 0);\n",
              "            return canvas.toDataURL('image/jpeg', 0.8);\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recognized: NIRAV_MISTRY (54%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function getFrame() {\n",
              "            if (!window.video) {\n",
              "                window.video = document.createElement('video');\n",
              "                window.video.srcObject = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                await window.video.play();\n",
              "            }\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = 640; canvas.height = 480;\n",
              "            canvas.getContext('2d').drawImage(window.video, 0, 0);\n",
              "            return canvas.toDataURL('image/jpeg', 0.8);\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recognized: NIRAV_MISTRY (57%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function getFrame() {\n",
              "            if (!window.video) {\n",
              "                window.video = document.createElement('video');\n",
              "                window.video.srcObject = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                await window.video.play();\n",
              "            }\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = 640; canvas.height = 480;\n",
              "            canvas.getContext('2d').drawImage(window.video, 0, 0);\n",
              "            return canvas.toDataURL('image/jpeg', 0.8);\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recognized: NIRAV_MISTRY (57%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function getFrame() {\n",
              "            if (!window.video) {\n",
              "                window.video = document.createElement('video');\n",
              "                window.video.srcObject = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                await window.video.play();\n",
              "            }\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = 640; canvas.height = 480;\n",
              "            canvas.getContext('2d').drawImage(window.video, 0, 0);\n",
              "            return canvas.toDataURL('image/jpeg', 0.8);\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1897955077.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# 1. Automatic frame capture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mimg_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb64decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3117147187.py\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     ''')\n\u001b[1;32m     17\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0meval_js\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'getFrame()'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# --- Main Logic ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}